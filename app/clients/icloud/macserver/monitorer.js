const path = require("path");
const readline = require("readline");
const Bottleneck = require("bottleneck");
const exec = require("./exec");
const { iCloudDriveDirectory } = require("./config");
const { spawn } = require("child_process");

const MAX_DEPTH = 1000;

const limiter = new Bottleneck({
  maxConcurrent: 5,
  minTime: 10, // 10ms between each call
});

// The purpose of this module is to keep iCloud Drive in sync
// and it achieves this by running `brctl monitor` to detect blog
// folders with changes and then it recursively lists their contents
// in order to force iCloud to sync the contents of the folder. It seems
// like using ls as opposed to readdir actually forces iCloud drive to
// push the names of new files and folders to the local system.

// If eventually we run into scaling issues with chokidar we could potentially
// use the information generated by this module to trigger syncs...
const recursiveListLimited = limiter.wrap(async function recursiveList(
  dirPath,
  depth = 0
) {
  if (depth > MAX_DEPTH) {
    console.warn(`Maximum depth ${MAX_DEPTH} reached at ${dirPath}`);
    return;
  }

  console.log(`ls: ${dirPath}`);

  let contents;

  try {
    const { stdout, stderr } = await exec("ls", ["-la1F", dirPath]);
    if (stderr) {
      throw new Error(`Error listing directory ${dirPath}: ${stderr}`);
    }
    contents = stdout;
  } catch (error) {
    // this error is expected if the directory is not downloaded
    if (error && !error.message.includes("Resource deadlock avoided")) {
      return console.error(
        `Error listing directory ${dirPath}: ${error.message}`
      );
    }

    try {
      // we need to try to download the directory first
      console.log(`Directory not downloaded, downloading: ${dirPath}`);
      await exec("brctl", ["download", dirPath]);
      // wait a moment for the download to complete
      await new Promise((resolve) => setTimeout(resolve, 1000));
      console.log(`Downloaded directory: ${dirPath}`);

      // re-attempt the ls
      const { stdout, stderr } = await exec("ls", ["-la1F", dirPath]);
      if (stderr) {
        throw new Error(`Error listing directory ${dirPath}: ${stderr}`);
      }
      contents = stdout;
    } catch (error) {
      return console.error(
        `Error listing directory ${dirPath} after download: ${error.message}`
      );
    }
  }

  try {
    const dirs = contents
      .split("\n")
      .filter((line) => line.endsWith("/")) // Only dirs end with /
      .map((line) => line.slice(0, -1)) // Remove trailing /
      .filter((name) => !name.startsWith(".")) // Skip anything starting with . (e.g. . and .. and .Trash)
      .map((name) => path.join(dirPath, name)); // Full path

    // Recurse into subdirectories in series
    for (const subDir of dirs) {
      await recursiveList(subDir, depth + 1);
    }
  } catch (error) {
    console.error("Error processing contents of directory", dirPath, error);
  }
});

module.exports = () => {
  function startMonitor() {
    const monitorProcess = spawn("brctl", [
      "monitor",
      "-i",
      iCloudDriveDirectory,
    ]);

    const rl = readline.createInterface({
      input: monitorProcess.stdout,
      crlfDelay: Infinity,
    });

    rl.on("line", (line) => {
      const match = line.match(/blog_[a-fA-F0-9]+/);
      if (match) {
        const blogId = match[0];
        console.log("Recursively listing contents of:", blogId);
        recursiveListLimited(`${iCloudDriveDirectory}/${blogId}`, 0).catch(
          (error) => {
            console.error(
              `Failed to recursively list contents of ${blogId}:`,
              error
            );
          }
        );
      }
    });

    monitorProcess.stderr.on("data", (data) => {
      console.error(`stderr: ${data}`);
    });

    monitorProcess.on("close", (code) => {
      rl.close();
      console.warn(
        `brctl monitor exited with code ${code}, restarting in 1s...`
      );
      setTimeout(startMonitor, 1000);
    });
  }

  startMonitor();
};
